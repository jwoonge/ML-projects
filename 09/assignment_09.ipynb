{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment-09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5lQGn84ZJoa7UrpvY3o1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwoonge/ML-projects/blob/master/09/assignment_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqqTw_oX1ljt"
      },
      "source": [
        "# Classification for Multiple Categories using Pytorch\n",
        "20141261 송제웅  \n",
        "<hr>  \n",
        "\n",
        "## 0. Import library\n",
        "---\n",
        "import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPDAp1r0pNn"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08y3CH6Y133C"
      },
      "source": [
        "# 1. DownLoad and Normalize dataset (MNIST)\n",
        "---  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXZSofdf05-r"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,),(0.3081,)),\n",
        "])\n",
        "\n",
        "data_path = './MNIST'\n",
        "data_train = datasets.MNIST(root = data_path, train = True, download = True, transform = transform)\n",
        "data_test = datasets.MNIST(root = data_path, train = False, download = True, transform = transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqOC-JTv2Q_7"
      },
      "source": [
        "## 2. Design NN Model\n",
        "---\n",
        "three fully connected layers with an activation function of sigmoid, LogSoftmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0wW9W8827VS"
      },
      "source": [
        "class classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(classification, self).__init__()\n",
        "        self.classifier1 = nn.Sequential(\n",
        "            nn.Linear(in_features=28*28, out_features=20*20),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.classifier2 = nn.Sequential(\n",
        "            nn.Linear(in_features=20*20, out_features=10*10),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.classifier3 = nn.Sequential(\n",
        "            nn.Linear(in_features=10*10, out_features=10),\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        )\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        x = inputs.view(inputs.size(0), -1)\n",
        "        x = self.classifier1(x)\n",
        "        x = self.classifier2(x)\n",
        "        out = self.classifier3(x)\n",
        "        return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YArDEad-lgtH"
      },
      "source": [
        "def train(model, train_loader, optimizer, criterion, device='cuda'):\n",
        "    #model.train()\n",
        "    n_batch = 0\n",
        "    avg_loss = 0\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = model.forward(x)\n",
        "        loss = criterion(pred, y)\n",
        "        avg_loss += loss\n",
        "        n_batch += 1\n",
        "    avg_loss /= n_batch\n",
        "\n",
        "def test(model, test_loader, device='cuda'):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70puj3LD-gC9"
      },
      "source": [
        "\n",
        "def learn(model, data_train, data_test, criterion, optimizer, batch_size, epoch, device='cuda'):\n",
        "    data_train_loader = torch.utils.data.DataLoader(data_train, batch_size)\n",
        "    #data_test_loader = torch.utils.data.DataLoader(data_test)\n",
        "    data_test = data_test.ToTensor()\n",
        "    torch.Size([batch_size, 1, 28, 28])\n",
        "    losses_train = []; losses_test = []; accuracies_train = []; accuracies_test = []\n",
        "    print(data_test)\n",
        "    for i in range(epoch):\n",
        "        n_batch = 0\n",
        "        loss_train = 0\n",
        "        for batch_idx, samples in enumerate(data_train_loader):\n",
        "            x_train, y_train = samples\n",
        "            x_train = x_train.to(device)\n",
        "            y_train = y_train.to(device)\n",
        "            pred = model.forward(x_train)\n",
        "            loss_train += criterion(pred, y_train)\n",
        "            n_batch += 1\n",
        "        pred_test = model.forward(data_test[:,0]).to(device)\n",
        "        loss_test = criterion(pred_test, data_test[:,1])\n",
        "        losses_train.append(loss_train/n_batch)\n",
        "        losses_test.append(loss_test)\n",
        "        print(losses_train[-1], losses_test[-1])\n",
        "    return losses_train"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAJOmBkx9vTk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "b2d31fdf-7b1e-4353-e2c6-4c56f90e18ee"
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')\n",
        "learning_rate = 0.01\n",
        "classifier = classification().to(device)\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "loss_train = learn(classifier, data_train, data_test, criterion, optimizer, 200, 20)\n",
        "plt.plot(loss_train)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-8f3e82364ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-08a7bf6b59fc>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(model, data_train, data_test, criterion, optimizer, batch_size, epoch, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata_train_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#data_test_loader = torch.utils.data.DataLoader(data_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlosses_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlosses_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0maccuracies_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0maccuracies_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MNIST' object has no attribute 'ToTensor'"
          ]
        }
      ]
    }
  ]
}