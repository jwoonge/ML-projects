{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment-09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiZ8IT7/U0D4Urf0cEbR5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwoonge/ML-projects/blob/master/09/assignment_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqqTw_oX1ljt"
      },
      "source": [
        "# Classification for Multiple Categories using Pytorch\n",
        "20141261 송제웅  \n",
        "<hr>  \n",
        "\n",
        "## 0. Import library\n",
        "---\n",
        "import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPDAp1r0pNn"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08y3CH6Y133C"
      },
      "source": [
        "# 1. DownLoad and Normalize dataset (MNIST)\n",
        "---  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXZSofdf05-r"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,),(0.3081,)),\n",
        "])\n",
        "\n",
        "data_path = './MNIST'\n",
        "data_train = datasets.MNIST(root = data_path, train = True, download = True, transform = transform)\n",
        "data_test = datasets.MNIST(root = data_path, train = False, download = True, transform = transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqOC-JTv2Q_7"
      },
      "source": [
        "## 2. Design NN Model\n",
        "---\n",
        "three fully connected layers with an activation function of sigmoid, LogSoftmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0wW9W8827VS"
      },
      "source": [
        "class classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(classification, self).__init__()\n",
        "        self.classifier1 = nn.Sequential(\n",
        "            nn.Linear(in_features=28*28, out_features=20*20),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.classifier2 = nn.Sequential(\n",
        "            nn.Linear(in_features=20*20, out_features=10*10),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.classifier3 = nn.Sequential(\n",
        "            nn.Linear(in_features=10*10, out_features=10),\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        )\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        x = inputs.view(inputs.size(0), -1)\n",
        "        x = self.classifier1(x)\n",
        "        x = self.classifier2(x)\n",
        "        out = self.classifier3(x)\n",
        "        return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YArDEad-lgtH"
      },
      "source": [
        "def train(model, data_train, data_train_batch, optimizer, criterion, device='cuda'):\n",
        "    n_batch = 0\n",
        "    avg_loss = 0\n",
        "    avg_acc = 0\n",
        "    for batch_idx, (x, y) in enumerate(data_train_batch):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model.forward(x)\n",
        "        loss = criterion(pred, y)\n",
        "        avg_loss += loss.item()\n",
        "        avg_acc += accuracy(pred, y)\n",
        "        n_batch += 1\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss /= n_batch\n",
        "    avg_acc /= n_batch\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "def test(model, x, y, criterion):\n",
        "    pred = model.forward(x)\n",
        "    loss = criterion(pred, y).item()\n",
        "    acc = accuracy(pred, y)\n",
        "    return loss, acc\n",
        "\n",
        "def accuracy(pred, y):\n",
        "    correct_cnt = 0\n",
        "    num_sample = len(y)\n",
        "    for i in range(num_sample):\n",
        "        pred_class = pred[i].argmax()\n",
        "        if y[i]==pred_class:\n",
        "            correct_cnt += 1\n",
        "    return 100 * correct_cnt / num_sample\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik0LrxaapEOl"
      },
      "source": [
        "def learn(model, data_train, data_test, criterion, optimizer, batch_size, epoch, device='cuda'):\n",
        "    data_train_batch = torch.utils.data.DataLoader(data_train, batch_size)\n",
        "    test_x, test_y = data_test.test_data.view((10000,28*28)), data_test.test_labels\n",
        "    test_x, test_y = torch.tensor(test_x, dtype=torch.float, device=device), test_y.to(device)\n",
        "    loss_train_s = []; loss_test_s = []; acc_train_s = []; acc_test_s = []\n",
        "    for i in range(epoch):\n",
        "        loss_test, acc_test = test(model, test_x, test_y, criterion)\n",
        "        loss_train, acc_train = train(model, data_train, data_train_batch, optimizer, criterion, device)\n",
        "        loss_train_s.append(loss_train); loss_test_s.append(loss_test)\n",
        "        acc_train_s.append(acc_train); acc_test_s.append(acc_test)\n",
        "    return loss_train_s, loss_test_s, acc_train_s, acc_test_s\n",
        "        "
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAJOmBkx9vTk"
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')\n",
        "learning_rate = 0.01\n",
        "classifier = classification().to(device)\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e4eNTcg8xu8",
        "outputId": "4c2a872c-5dab-4adb-c5d7-2c5c943f8d0f"
      },
      "source": [
        "loss_train_32, loss_test_32, acc_train_32, acc_test_32 = learn(classifier, data_train, data_test, criterion, optimizer, 32, 20)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s86AxgoB8yNU"
      },
      "source": [
        "loss_train_64, loss_test_64, acc_train_64, acc_test_64 = learn(classifier, data_train, data_test, criterion, optimizer, 32, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc30AePg8zEH"
      },
      "source": [
        "loss_train_128, loss_test_128, acc_train_128, acc_test_128 = learn(classifier, data_train, data_test, criterion, optimizer, 32, 20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}