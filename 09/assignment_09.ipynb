{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment-09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPx8mtTA+0LaZi1oZwiH7Ix",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwoonge/ML-projects/blob/master/09/assignment_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqqTw_oX1ljt"
      },
      "source": [
        "# Classification for Multiple Categories using Pytorch\n",
        "20141261 송제웅  \n",
        "<hr>  \n",
        "\n",
        "## 0. Import library\n",
        "---\n",
        "import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPDAp1r0pNn"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08y3CH6Y133C"
      },
      "source": [
        "# 1. DownLoad and Normalize dataset (MNIST)\n",
        "---  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXZSofdf05-r"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,),(0.3081,)),\n",
        "])\n",
        "\n",
        "data_path = './MNIST'\n",
        "data_train = datasets.MNIST(root = data_path, train = True, download = True, transform = transform)\n",
        "data_test = datasets.MNIST(root = data_path, train = False, download = True, transform = transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqOC-JTv2Q_7"
      },
      "source": [
        "## 2. Design NN Model\n",
        "---\n",
        "three fully connected layers with an activation function of sigmoid, LogSoftmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0wW9W8827VS"
      },
      "source": [
        "class classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(classification, self).__init__()\n",
        "        self.classifier1 = nn.Sequential(\n",
        "            nn.Linear(in_features=28*28, out_features=20*20),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.classifier2 = nn.Sequential(\n",
        "            nn.Linear(in_features=20*20, out_features=10*10),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.classifier3 = nn.Sequential(\n",
        "            nn.Linear(in_features=10*10, out_features=10),\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        )\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        x = inputs.view(inputs.size(0), -1)\n",
        "        x = self.classifier1(x)\n",
        "        x = self.classifier2(x)\n",
        "        out = self.classifier3(x)\n",
        "        return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YArDEad-lgtH"
      },
      "source": [
        "def train(model, data_train, data_train_batch, optimizer, criterion, device='cuda'):\n",
        "    n_batch = 0\n",
        "    avg_loss = 0\n",
        "    for batch_idx, (x, y) in enumerate(data_train_batch):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model.forward(x)\n",
        "        loss = criterion(pred, y)\n",
        "        avg_loss += loss.item()\n",
        "        n_batch += 1\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss /= n_batch\n",
        "    return avg_loss, 0\n",
        "\n",
        "def test(model, x, y, criterion):\n",
        "    pred = model.forward(x)\n",
        "    loss = criterion(pred, y).item()\n",
        "    acc = accuracy(pred, y)\n",
        "    return loss, acc\n",
        "\n",
        "def accuracy(pred, y):\n",
        "    return 0\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik0LrxaapEOl"
      },
      "source": [
        "def learn(model, data_train, data_test, criterion, optimizer, batch_size, epoch, device='cuda'):\n",
        "    data_train_batch = torch.utils.data.DataLoader(data_train, batch_size)\n",
        "    test_x, test_y = data_test.test_data.view((10000,28*28)), data_test.test_labels\n",
        "    test_x, test_y = torch.tensor(test_x, dtype=torch.float, device=device), test_y.to(device)\n",
        "    #data_test = torch.utils.data.DataLoader(data_test)\n",
        "    #data_train = torch.utils.data.DataLoader(data_train)\n",
        "\n",
        "    for i in range(epoch):\n",
        "        loss_test, acc_test = test(model, test_x, test_y, criterion)\n",
        "        loss_train, acc_train = train(model, data_train, data_train_batch, optimizer, criterion, device)\n",
        "        \n",
        "        print(loss_train, acc_train, loss_test, acc_test)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAJOmBkx9vTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bde564-5f1e-4ff7-cd5e-bb4452f0e031"
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')\n",
        "learning_rate = 0.01\n",
        "classifier = classification().to(device)\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "learn(classifier, data_train, data_test, criterion, optimizer, 32, 20)\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.1755596171696983 0 2.333524465560913 0\n",
            "1.294482604344686 0 1.6375123262405396 0\n",
            "0.7217436532815298 0 0.8274950385093689 0\n",
            "0.5292548909187317 0 0.6071614623069763 0\n",
            "0.44037941915591555 0 0.5486127138137817 0\n",
            "0.39078929236332577 0 0.5302201509475708 0\n",
            "0.3592618755221367 0 0.5172317624092102 0\n",
            "0.33668616591095923 0 0.4973558485507965 0\n",
            "0.31892089071273805 0 0.47201406955718994 0\n",
            "0.3039793945332368 0 0.444766104221344 0\n",
            "0.2908338331659635 0 0.41522759199142456 0\n",
            "0.2789111590375503 0 0.39019688963890076 0\n",
            "0.2678733481556177 0 0.3678288757801056 0\n",
            "0.25751489926775295 0 0.3451109230518341 0\n",
            "0.2477103613058726 0 0.32400816679000854 0\n",
            "0.23838455685476462 0 0.30502593517303467 0\n",
            "0.2294941013286511 0 0.28766581416130066 0\n",
            "0.22101527601778506 0 0.2721858024597168 0\n",
            "0.21293542516628902 0 0.25967171788215637 0\n",
            "0.2052463561475277 0 0.24845734238624573 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}