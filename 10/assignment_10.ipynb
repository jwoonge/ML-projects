{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwoonge/ML-projects/blob/master/10/assignment_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqqTw_oX1ljt"
      },
      "source": [
        "# Optimal Selection of the hyper-parameters associated with the classification on MNIST\n",
        "20141261 송제웅  \n",
        "<hr>  \n",
        "\n",
        "## 0. Import library\n",
        "---\n",
        "import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPDAp1r0pNn"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08y3CH6Y133C"
      },
      "source": [
        "## 1. DownLoad and Normalize dataset (MNIST)\n",
        "---  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXZSofdf05-r"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,),(0.3081,)),\n",
        "])\n",
        "\n",
        "data_path = './MNIST'\n",
        "data_train = datasets.MNIST(root = data_path, train = False, download = True, transform = transform)\n",
        "data_test = datasets.MNIST(root = data_path, train = True, download = True, transform = transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqOC-JTv2Q_7"
      },
      "source": [
        "## 2. Design NN Model\n",
        "---\n",
        "three fully connected layers with an activation function of sigmoid, LogSoftmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0wW9W8827VS"
      },
      "source": [
        "class classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(classification, self).__init__()\n",
        "        self.classifier1 = nn.Sequential(\n",
        "            nn.Linear(in_features=28*28, out_features=64),\n",
        "            #nn.Softsign(),\n",
        "            #nn.Sigmoid()\n",
        "            nn.ELU()\n",
        "        )\n",
        "        \n",
        "        self.classifier2 = nn.Sequential(\n",
        "            nn.Linear(in_features=64, out_features=48),\n",
        "            #nn.Softsign(),\n",
        "            #nn.Sigmoid()\n",
        "            nn.ELU()\n",
        "        )\n",
        "        \n",
        "        self.classifier3 = nn.Sequential(\n",
        "            nn.Linear(in_features=48, out_features=10),\n",
        "            nn.LogSoftmax(dim=1),\n",
        "        )\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        x = inputs.view(inputs.size(0), -1)\n",
        "        x = self.classifier1(x)\n",
        "        x = self.classifier2(x)\n",
        "        out = self.classifier3(x)\n",
        "        return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFCxCJ40Dd4z"
      },
      "source": [
        "## 3. Define functions for learning\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YArDEad-lgtH"
      },
      "source": [
        "def train(model, data_train, data_train_batch, optimizer, criterion, device='cuda'):\n",
        "    model.train()\n",
        "    n_batch = 0\n",
        "    avg_loss = 0\n",
        "    avg_acc = 0\n",
        "    for batch_idx, (x, y) in enumerate(data_train_batch):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model.forward(x)\n",
        "        loss = criterion(pred, y)\n",
        "        avg_loss += loss.item()\n",
        "        avg_acc += accuracy(pred, y)\n",
        "        n_batch += 1\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss /= n_batch\n",
        "    avg_acc /= n_batch\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "def test(model, x, y, criterion):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model.forward(x)\n",
        "        loss = criterion(pred, y).item()\n",
        "        acc = accuracy(pred, y)\n",
        "    return loss, acc\n",
        "\n",
        "def accuracy(pred, y):\n",
        "    correct_cnt = 0\n",
        "    num_sample = len(y)\n",
        "    for i in range(num_sample):\n",
        "        pred_class = pred[i].argmax()\n",
        "        if y[i]==pred_class:\n",
        "            correct_cnt += 1\n",
        "    return 100 * correct_cnt / num_sample\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik0LrxaapEOl"
      },
      "source": [
        "def learn(model, data_train, data_test, criterion, optimizer, batch_size, epoch, device='cuda'):\n",
        "    data_train_batch = torch.utils.data.DataLoader(data_train, batch_size, shuffle=True)\n",
        "    test_x, test_y = data_test.test_data.view((60000,28*28)), data_test.test_labels\n",
        "    test_x, test_y = torch.tensor(test_x, dtype=torch.float, device=device), test_y.to(device)\n",
        "    #loss_train_s = []; loss_test_s = []; acc_train_s = []; acc_test_s = []\n",
        "    i = 0\n",
        "    while i<epoch:\n",
        "        losstest, acctest = test(model, test_x, test_y, criterion)\n",
        "        losstrain, acctrain = train(model, data_train, data_train_batch, optimizer, criterion, device)\n",
        "        loss_train.append(losstrain); loss_test.append(losstest)\n",
        "        acc_train.append(acctrain); acc_test.append(acctest)\n",
        "        i += 1\n",
        "        print(i,'\\t', losstrain,'\\t', acctrain,'\\t', losstest,'\\t', acctest)\n",
        "        "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAJOmBkx9vTk"
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofQ6try_DkHj"
      },
      "source": [
        "## 4. Learn\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e4eNTcg8xu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf27b1b-1faa-4224-faf8-057b8beac4fd"
      },
      "source": [
        "global loss_train, loss_test, acc_train, acc_test\n",
        "loss_train = []; loss_test = []; acc_train = []; acc_test = []\n",
        "classifier = classification().to(device)\n",
        "optimizer = torch.optim.Adadelta(classifier.parameters(), lr=20, weight_decay=0.0001)\n",
        "criterion = nn.NLLLoss()\n",
        "learn(classifier, data_train, data_test, criterion, optimizer, 10000, 5, device)\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.3, weight_decay=0.0005)\n",
        "learn(classifier, data_train, data_test, criterion, optimizer, 10000, 5, device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 \t 2.34045147895813 \t 8.32 \t 11.430671691894531 \t 11.488333333333333\n",
            "2 \t 3.3449699878692627 \t 28.47 \t 253.22015380859375 \t 20.54\n",
            "3 \t 21.65400505065918 \t 11.29 \t 1194.865966796875 \t 11.553333333333333\n",
            "4 \t 27.270252227783203 \t 10.1 \t 1534.3814697265625 \t 10.255\n",
            "5 \t 18.187101364135742 \t 17.37 \t 820.8509521484375 \t 18.661666666666665\n",
            "1 \t 18.01138687133789 \t 8.92 \t 634.569580078125 \t 11.435\n",
            "2 \t 9.021909713745117 \t 15.65 \t 412.2015380859375 \t 18.291666666666668\n",
            "3 \t 11.0753812789917 \t 16.8 \t 241.466552734375 \t 23.98\n",
            "4 \t 3.461045742034912 \t 29.5 \t 207.7643280029297 \t 24.586666666666666\n",
            "5 \t 5.405007362365723 \t 28.56 \t 185.74871826171875 \t 27.321666666666665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrGjiBfQDuZD"
      },
      "source": [
        "---  \n",
        "# RESULTS\n",
        "---  \n",
        "## 1. Plot the training and testing losses over epochs\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHQlI0J1Wdk6"
      },
      "source": [
        "plt.plot(loss_train, color='r')\n",
        "plt.plot(loss_test, color='b')\n",
        "plt.title('loss')\n",
        "plt.legend(['train','test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOT4D0XEBdm6"
      },
      "source": [
        "## 2. Plot the training and testing accuracies over epochs\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE1Ap8q0XX3q"
      },
      "source": [
        "plt.plot(acc_train, color='r')\n",
        "plt.plot(acc_test, color='b')\n",
        "plt.title('accuracy(%)')\n",
        "plt.legend(['train','test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUW2uhsGEcxb"
      },
      "source": [
        "## 3. Print the final training and testing losses at convergence\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q2l_i1yHvBW"
      },
      "source": [
        "print('training loss\\t',loss_train[-1])\n",
        "print('testing loss\\t',loss_test[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5hSy5XwEhgr"
      },
      "source": [
        "## 4. Print the final training and testing accuracies at convergence\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE3PebMzITtm"
      },
      "source": [
        "print('training accuracy\\t',acc_train[-1])\n",
        "print('testing accuracy\\t',acc_test[-1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}